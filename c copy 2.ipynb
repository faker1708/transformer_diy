{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# import time\n",
    "\n",
    "class NWKernelRegression(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = nn.Parameter(torch.rand((1,), requires_grad=True))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries和attention_weights的形状为(查询个数，“键－值”对个数)\n",
    "        queries = queries.repeat_interleave(keys.shape[1]).reshape((-1, keys.shape[1]))\n",
    "        self.attention_weights = nn.functional.softmax(\n",
    "            -((queries - keys) * self.w)**2 / 2, dim=1)\n",
    "        # values的形状为(查询个数，“键－值”对个数)\n",
    "        return torch.bmm(self.attention_weights.unsqueeze(1),\n",
    "                         values.unsqueeze(-1)).reshape(-1)\n",
    "    \n",
    "\n",
    "class class_a():\n",
    "\n",
    "    def plot_kernel_reg(self,x_test,y_hat,y_truth,x_train, y_train):\n",
    "        d2l.plot(x_test, [y_truth, y_hat], 'x', 'y', legend=['Truth', 'Pred'],\n",
    "                xlim=[0, 5], ylim=[-1, 5])\n",
    "        d2l.plt.plot(x_train, y_train, 'o', alpha=0.5);\n",
    "\n",
    "    def f(self,x):\n",
    "        return 2 * torch.sin(x) + x**0.8\n",
    "\n",
    "    def __init__(self):\n",
    "        self.main()\n",
    "\n",
    "\n",
    "    def avg_pooling(self,x_test,y_hat,y_truth,x_train, y_train):\n",
    "        \n",
    "        n_test = len(x_test)  # 测试样本数\n",
    "        print('平均汇聚')\n",
    "        y_hat = torch.repeat_interleave(y_train.mean(), n_test)\n",
    "        self.plot_kernel_reg(x_test,y_hat,y_truth,x_train, y_train)\n",
    "        # time.sleep(1)\n",
    "\n",
    "\n",
    "    def no_para_pooling(self,x_test,y_hat,y_truth,x_train, y_train):\n",
    "    \n",
    "        n_train = self.n_train  # 训练样本数\n",
    "\n",
    "\n",
    "        print('无参汇聚')\n",
    "        # X_repeat的形状:(n_test,n_train),\n",
    "        # 每一行都包含着相同的测试输入（例如：同样的查询）\n",
    "        X_repeat = x_test.repeat_interleave(n_train).reshape((-1, n_train))\n",
    "        # x_train包含着键。attention_weights的形状：(n_test,n_train),\n",
    "        # 每一行都包含着要在给定的每个查询的值（y_train）之间分配的注意力权重\n",
    "        attention_weights = nn.functional.softmax(-(X_repeat - x_train)**2 / 2, dim=1)\n",
    "        # y_hat的每个元素都是值的加权平均值，其中的权重是注意力权重\n",
    "        y_hat = torch.matmul(attention_weights, y_train)\n",
    "        self.plot_kernel_reg(x_test,y_hat,y_truth,x_train, y_train)\n",
    "        # self.plot_kernel_reg(y_hat)\n",
    "\n",
    "\n",
    "        d2l.show_heatmaps(attention_weights.unsqueeze(0).unsqueeze(0),\n",
    "                    xlabel='Sorted training inputs',\n",
    "                    ylabel='Sorted testing inputs')\n",
    "        \n",
    "\n",
    "\n",
    "    def para_pooling(self,x_test,y_hat,y_truth,x_train, y_train):\n",
    "        print('含参汇聚')\n",
    "        n_train = self.n_train  # 训练样本数\n",
    "        n_test = len(x_test)  # 测试样本数\n",
    "\n",
    "\n",
    "        X = torch.ones((2, 1, 4))\n",
    "        Y = torch.ones((2, 4, 6))\n",
    "        torch.bmm(X, Y).shape\n",
    "\n",
    "\n",
    "        weights = torch.ones((2, 10)) * 0.1\n",
    "        values = torch.arange(20.0).reshape((2, 10))\n",
    "        torch.bmm(weights.unsqueeze(1), values.unsqueeze(-1))\n",
    "\n",
    "\n",
    "\n",
    "        # X_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输入\n",
    "        X_tile = x_train.repeat((n_train, 1))\n",
    "        # Y_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输出\n",
    "        Y_tile = y_train.repeat((n_train, 1))\n",
    "        # keys的形状:('n_train'，'n_train'-1)\n",
    "        keys = X_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))\n",
    "        # values的形状:('n_train'，'n_train'-1)\n",
    "        values = Y_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))\n",
    "\n",
    "        net = NWKernelRegression()\n",
    "        loss = nn.MSELoss(reduction='none')\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "        animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[1, 5])\n",
    "\n",
    "        train_count = 2**5\n",
    "\n",
    "        for epoch in range(train_count):\n",
    "            print(epoch)\n",
    "            trainer.zero_grad()\n",
    "            l = loss(net(x_train, keys, values), y_train)\n",
    "\n",
    "            # print('loss',float(l))\n",
    "            # print('loss',l)\n",
    "            input('wefoewio')\n",
    "            loss_tensor = l.sum()\n",
    "            # l.sum().backward()\n",
    "            loss_tensor.backward()\n",
    "            # loss = float(loss_tensor)\n",
    "            losstt = loss_tensor.to('cpu')\n",
    "            print('loss',losstt)\n",
    "\n",
    "            trainer.step()\n",
    "            print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}')\n",
    "            animator.add(epoch + 1, float(l.sum()))\n",
    "\n",
    "\n",
    "\n",
    "        # keys的形状:(n_test，n_train)，每一行包含着相同的训练输入（例如，相同的键）\n",
    "        keys = x_train.repeat((n_test, 1))\n",
    "        # value的形状:(n_test，n_train)\n",
    "        values = y_train.repeat((n_test, 1))\n",
    "        y_hat = net(x_test, keys, values).unsqueeze(1).detach()\n",
    "        # self.plot_kernel_reg(y_hat)\n",
    "        self.plot_kernel_reg(x_test,y_hat,y_truth,x_train, y_train)\n",
    "\n",
    "        d2l.show_heatmaps(net.attention_weights.unsqueeze(0).unsqueeze(0),\n",
    "                  xlabel='Sorted training inputs',\n",
    "                  ylabel='Sorted testing inputs')\n",
    "\n",
    "    def main(self,):\n",
    "\n",
    "        self.n_train = 50  # 训练样本数\n",
    "        n_train = self.n_train  # 训练样本数\n",
    "\n",
    "\n",
    "        x_train, _ = torch.sort(torch.rand(n_train) * 5)   # 排序后的训练样本\n",
    "        # x_train = torch.rand(n_train) * 5  # 排序后的训练样本\n",
    "\n",
    "\n",
    "        y_train = self.f(x_train) + torch.normal(0.0, 0.5, (n_train,))  # 训练样本的输出\n",
    "        x_test = torch.arange(0, 5, 0.1)  # 测试样本\n",
    "        y_truth = self.f(x_test)  # 测试样本的真实输出\n",
    "        n_test = len(x_test)  # 测试样本数\n",
    "        # print(n_test)\n",
    "\n",
    "        print('xt',x_train)\n",
    "        y_hat = 0\n",
    "        self.para_pooling(x_test,y_hat,y_truth,x_train, y_train)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    class_a()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
